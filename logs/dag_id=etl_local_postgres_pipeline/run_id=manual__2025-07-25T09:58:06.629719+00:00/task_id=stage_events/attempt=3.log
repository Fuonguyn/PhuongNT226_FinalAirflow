[2025-07-25T17:08:59.284+0700] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_local_postgres_pipeline.stage_events manual__2025-07-25T09:58:06.629719+00:00 [queued]>
[2025-07-25T17:08:59.539+0700] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_local_postgres_pipeline.stage_events manual__2025-07-25T09:58:06.629719+00:00 [queued]>
[2025-07-25T17:08:59.540+0700] {taskinstance.py:2170} INFO - Starting attempt 3 of 4
[2025-07-25T17:09:00.675+0700] {taskinstance.py:2191} INFO - Executing <Task(PythonOperator): stage_events> on 2025-07-25 09:58:06.629719+00:00
[2025-07-25T17:09:00.692+0700] {standard_task_runner.py:60} INFO - Started process 16514 to run task
[2025-07-25T17:09:00.700+0700] {standard_task_runner.py:87} INFO - Running: ['airflow', 'tasks', 'run', 'etl_local_postgres_pipeline', 'stage_events', 'manual__2025-07-25T09:58:06.629719+00:00', '--job-id', '37', '--raw', '--subdir', 'DAGS_FOLDER/etl_pipeline_pjt.py', '--cfg-path', '/tmp/tmprc_9uq29']
[2025-07-25T17:09:00.707+0700] {standard_task_runner.py:88} INFO - Job 37: Subtask stage_events
[2025-07-25T17:09:06.759+0700] {task_command.py:423} INFO - Running <TaskInstance: etl_local_postgres_pipeline.stage_events manual__2025-07-25T09:58:06.629719+00:00 [running]> on host DESKTOP-9M5T9P5.localdomain
[2025-07-25T17:09:11.030+0700] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='phuongnt226' AIRFLOW_CTX_DAG_ID='etl_local_postgres_pipeline' AIRFLOW_CTX_TASK_ID='stage_events' AIRFLOW_CTX_EXECUTION_DATE='2025-07-25T09:58:06.629719+00:00' AIRFLOW_CTX_TRY_NUMBER='3' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-07-25T09:58:06.629719+00:00'
[2025-07-25T17:09:12.648+0700] {logging_mixin.py:188} INFO - Find out 30 envent files.
[2025-07-25T17:38:31.162+0700] {logging_mixin.py:188} INFO - Close connection to stage_events.
[2025-07-25T17:38:31.257+0700] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/operators/python.py", line 199, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/operators/python.py", line 216, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/dags/etl_pipeline_pjt.py", line 74, in stage_events_to_postgres
    cur.execute("""
psycopg2.OperationalError: server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.

[2025-07-25T17:38:33.293+0700] {taskinstance.py:1138} INFO - Marking task as UP_FOR_RETRY. dag_id=etl_local_postgres_pipeline, task_id=stage_events, execution_date=20250725T095806, start_date=20250725T100859, end_date=20250725T103833
[2025-07-25T17:38:34.218+0700] {standard_task_runner.py:107} ERROR - Failed to execute job 37 for task stage_events (server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.
server closed the connection unexpectedly
	This probably means the server terminated abnormally
	before or while processing the request.
; 16514)
[2025-07-25T17:38:34.251+0700] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2025-07-25T17:38:35.116+0700] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
