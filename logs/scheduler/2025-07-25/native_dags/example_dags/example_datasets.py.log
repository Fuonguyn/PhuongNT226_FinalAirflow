[2025-07-25T15:31:50.328+0700] {processor.py:161} INFO - Started process (PID=7105) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:31:50.328+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T15:31:50.329+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:31:50.329+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:31:50.339+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:31:50.417+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:31:50.417+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T15:31:50.430+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:31:50.430+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T15:31:50.432+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:31:50.432+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T15:31:50.433+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:31:50.433+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T15:31:50.434+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:31:50.434+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T15:31:50.436+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:31:50.436+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T15:31:50.437+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:31:50.437+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T15:31:50.548+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.223 seconds
[2025-07-25T15:32:46.450+0700] {processor.py:161} INFO - Started process (PID=7163) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:32:46.452+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T15:32:46.453+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:32:46.452+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:32:46.461+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:32:46.481+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:32:46.481+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T15:32:46.496+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:32:46.495+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T15:32:46.498+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:32:46.498+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T15:32:46.499+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:32:46.498+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T15:32:46.499+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:32:46.499+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T15:32:46.501+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:32:46.500+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T15:32:46.501+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:32:46.501+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T15:32:46.528+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.080 seconds
[2025-07-25T15:33:38.464+0700] {processor.py:161} INFO - Started process (PID=7219) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:33:38.465+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T15:33:38.465+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:33:38.465+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:33:38.473+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:33:38.492+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:33:38.492+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T15:33:38.508+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:33:38.508+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T15:33:38.584+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:33:38.583+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T15:33:38.584+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:33:38.584+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T15:33:38.585+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:33:38.585+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T15:33:38.586+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:33:38.586+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T15:33:38.587+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:33:38.587+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T15:33:38.609+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.148 seconds
[2025-07-25T15:34:30.464+0700] {processor.py:161} INFO - Started process (PID=7294) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:34:30.465+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T15:34:30.465+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:34:30.465+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:34:30.474+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:34:30.494+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:34:30.494+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T15:34:30.509+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:34:30.509+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T15:34:30.512+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:34:30.512+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T15:34:30.512+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:34:30.512+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T15:34:30.513+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:34:30.513+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T15:34:30.515+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:34:30.515+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T15:34:30.515+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:34:30.515+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T15:34:30.538+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.077 seconds
[2025-07-25T15:35:15.131+0700] {processor.py:161} INFO - Started process (PID=7345) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:35:15.134+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T15:35:15.135+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:35:15.135+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:35:15.147+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:35:15.167+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:35:15.167+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T15:35:15.181+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:35:15.181+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T15:35:15.183+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:35:15.183+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T15:35:15.184+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:35:15.184+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T15:35:15.184+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:35:15.184+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T15:35:15.186+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:35:15.185+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T15:35:15.186+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:35:15.186+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T15:35:15.207+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.079 seconds
[2025-07-25T15:35:57.017+0700] {processor.py:161} INFO - Started process (PID=7398) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:35:57.020+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T15:35:57.022+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:35:57.022+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:35:57.033+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:35:57.059+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:35:57.059+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T15:35:57.073+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:35:57.073+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T15:35:57.075+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:35:57.075+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T15:35:57.076+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:35:57.076+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T15:35:57.076+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:35:57.076+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T15:35:57.078+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:35:57.078+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T15:35:57.078+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:35:57.078+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T15:35:57.099+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.085 seconds
[2025-07-25T15:36:41.224+0700] {processor.py:161} INFO - Started process (PID=7453) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:36:41.225+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T15:36:41.226+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:36:41.225+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:36:41.235+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:36:41.257+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:36:41.257+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T15:36:41.274+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:36:41.274+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T15:36:41.276+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:36:41.276+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T15:36:41.277+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:36:41.277+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T15:36:41.278+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:36:41.278+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T15:36:41.281+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:36:41.281+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T15:36:41.282+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:36:41.282+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T15:36:41.309+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 0.089 seconds
[2025-07-25T15:40:50.118+0700] {processor.py:161} INFO - Started process (PID=7722) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:40:50.119+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T15:40:50.120+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:40:50.120+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:40:50.129+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:40:52.665+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:40:52.664+0700] {override.py:1769} INFO - Created Permission View: can read on DAG:dataset_consumes_unknown_never_scheduled
[2025-07-25T15:40:53.287+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:40:53.287+0700] {override.py:1769} INFO - Created Permission View: can edit on DAG:dataset_consumes_unknown_never_scheduled
[2025-07-25T15:40:53.882+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:40:53.882+0700] {override.py:1769} INFO - Created Permission View: can delete on DAG:dataset_consumes_unknown_never_scheduled
[2025-07-25T15:40:54.821+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:40:54.821+0700] {override.py:1769} INFO - Created Permission View: can read on DAG:dataset_consumes_1
[2025-07-25T15:40:55.245+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:40:55.245+0700] {override.py:1769} INFO - Created Permission View: can edit on DAG:dataset_consumes_1
[2025-07-25T15:40:55.694+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:40:55.694+0700] {override.py:1769} INFO - Created Permission View: can delete on DAG:dataset_consumes_1
[2025-07-25T15:40:56.443+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:40:56.442+0700] {override.py:1769} INFO - Created Permission View: can read on DAG:dataset_consumes_1_never_scheduled
[2025-07-25T15:40:56.857+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:40:56.857+0700] {override.py:1769} INFO - Created Permission View: can edit on DAG:dataset_consumes_1_never_scheduled
[2025-07-25T15:40:57.276+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:40:57.276+0700] {override.py:1769} INFO - Created Permission View: can delete on DAG:dataset_consumes_1_never_scheduled
[2025-07-25T15:40:58.018+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:40:58.018+0700] {override.py:1769} INFO - Created Permission View: can read on DAG:dataset_produces_1
[2025-07-25T15:40:58.432+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:40:58.432+0700] {override.py:1769} INFO - Created Permission View: can edit on DAG:dataset_produces_1
[2025-07-25T15:40:58.856+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:40:58.856+0700] {override.py:1769} INFO - Created Permission View: can delete on DAG:dataset_produces_1
[2025-07-25T15:40:59.599+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:40:59.599+0700] {override.py:1769} INFO - Created Permission View: can read on DAG:dataset_consumes_1_and_2
[2025-07-25T15:41:00.262+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:41:00.261+0700] {override.py:1769} INFO - Created Permission View: can edit on DAG:dataset_consumes_1_and_2
[2025-07-25T15:41:00.924+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:41:00.923+0700] {override.py:1769} INFO - Created Permission View: can delete on DAG:dataset_consumes_1_and_2
[2025-07-25T15:41:01.979+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:41:01.979+0700] {override.py:1769} INFO - Created Permission View: can read on DAG:dataset_produces_2
[2025-07-25T15:41:02.497+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:41:02.497+0700] {override.py:1769} INFO - Created Permission View: can edit on DAG:dataset_produces_2
[2025-07-25T15:41:03.006+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:41:03.006+0700] {override.py:1769} INFO - Created Permission View: can delete on DAG:dataset_produces_2
[2025-07-25T15:41:03.006+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:41:03.006+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T15:41:03.303+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:41:03.303+0700] {dag.py:3058} INFO - Creating ORM DAG for dataset_consumes_1_never_scheduled
[2025-07-25T15:41:03.304+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:41:03.304+0700] {dag.py:3058} INFO - Creating ORM DAG for dataset_consumes_unknown_never_scheduled
[2025-07-25T15:41:03.304+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:41:03.304+0700] {dag.py:3058} INFO - Creating ORM DAG for dataset_consumes_1
[2025-07-25T15:41:03.304+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:41:03.304+0700] {dag.py:3058} INFO - Creating ORM DAG for dataset_produces_1
[2025-07-25T15:41:03.305+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:41:03.305+0700] {dag.py:3058} INFO - Creating ORM DAG for dataset_consumes_1_and_2
[2025-07-25T15:41:03.305+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:41:03.305+0700] {dag.py:3058} INFO - Creating ORM DAG for dataset_produces_2
[2025-07-25T15:41:03.474+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:41:03.474+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T15:41:03.475+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:41:03.475+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T15:41:03.475+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:41:03.475+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T15:41:03.475+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:41:03.475+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T15:41:03.477+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:41:03.476+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T15:41:03.477+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:41:03.477+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T15:41:05.769+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 15.654 seconds
[2025-07-25T15:42:40.102+0700] {processor.py:161} INFO - Started process (PID=7979) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:42:40.103+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T15:42:40.104+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:42:40.104+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:42:40.112+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:42:42.364+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:42:42.364+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T15:42:42.547+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:42:42.547+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T15:42:42.670+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:42:42.670+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T15:42:42.718+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:42:42.717+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T15:42:42.764+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:42:42.764+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T15:42:42.821+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:42:42.821+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T15:42:42.891+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:42:42.891+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T15:54:42.988+0700] {processor.py:161} INFO - Started process (PID=8342) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:54:42.990+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T15:54:42.990+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:42.990+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:54:43.003+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:54:46.324+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:46.323+0700] {override.py:1769} INFO - Created Permission View: can edit on DAG:dataset_consumes_1
[2025-07-25T15:54:46.869+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:46.868+0700] {override.py:1769} INFO - Created Permission View: can read on DAG:dataset_consumes_1
[2025-07-25T15:54:47.402+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:47.402+0700] {override.py:1769} INFO - Created Permission View: can delete on DAG:dataset_consumes_1
[2025-07-25T15:54:48.322+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:48.322+0700] {override.py:1769} INFO - Created Permission View: can edit on DAG:dataset_produces_2
[2025-07-25T15:54:48.854+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:48.853+0700] {override.py:1769} INFO - Created Permission View: can read on DAG:dataset_produces_2
[2025-07-25T15:54:49.338+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:49.338+0700] {override.py:1769} INFO - Created Permission View: can delete on DAG:dataset_produces_2
[2025-07-25T15:54:50.209+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:50.209+0700] {override.py:1769} INFO - Created Permission View: can edit on DAG:dataset_consumes_1_never_scheduled
[2025-07-25T15:54:50.698+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:50.698+0700] {override.py:1769} INFO - Created Permission View: can read on DAG:dataset_consumes_1_never_scheduled
[2025-07-25T15:54:51.191+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:51.191+0700] {override.py:1769} INFO - Created Permission View: can delete on DAG:dataset_consumes_1_never_scheduled
[2025-07-25T15:54:52.452+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:52.452+0700] {override.py:1769} INFO - Created Permission View: can edit on DAG:dataset_consumes_1_and_2
[2025-07-25T15:54:52.944+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:52.944+0700] {override.py:1769} INFO - Created Permission View: can read on DAG:dataset_consumes_1_and_2
[2025-07-25T15:54:53.493+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:53.493+0700] {override.py:1769} INFO - Created Permission View: can delete on DAG:dataset_consumes_1_and_2
[2025-07-25T15:54:54.365+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:54.364+0700] {override.py:1769} INFO - Created Permission View: can edit on DAG:dataset_consumes_unknown_never_scheduled
[2025-07-25T15:54:54.842+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:54.842+0700] {override.py:1769} INFO - Created Permission View: can read on DAG:dataset_consumes_unknown_never_scheduled
[2025-07-25T15:54:55.335+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:55.335+0700] {override.py:1769} INFO - Created Permission View: can delete on DAG:dataset_consumes_unknown_never_scheduled
[2025-07-25T15:54:56.194+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:56.194+0700] {override.py:1769} INFO - Created Permission View: can edit on DAG:dataset_produces_1
[2025-07-25T15:54:56.687+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:56.686+0700] {override.py:1769} INFO - Created Permission View: can read on DAG:dataset_produces_1
[2025-07-25T15:54:57.169+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:57.169+0700] {override.py:1769} INFO - Created Permission View: can delete on DAG:dataset_produces_1
[2025-07-25T15:54:57.170+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:57.170+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T15:54:57.337+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:57.337+0700] {dag.py:3058} INFO - Creating ORM DAG for dataset_produces_2
[2025-07-25T15:54:57.338+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:57.338+0700] {dag.py:3058} INFO - Creating ORM DAG for dataset_produces_1
[2025-07-25T15:54:57.338+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:57.338+0700] {dag.py:3058} INFO - Creating ORM DAG for dataset_consumes_1_never_scheduled
[2025-07-25T15:54:57.339+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:57.338+0700] {dag.py:3058} INFO - Creating ORM DAG for dataset_consumes_1
[2025-07-25T15:54:57.339+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:57.339+0700] {dag.py:3058} INFO - Creating ORM DAG for dataset_consumes_1_and_2
[2025-07-25T15:54:57.339+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:57.339+0700] {dag.py:3058} INFO - Creating ORM DAG for dataset_consumes_unknown_never_scheduled
[2025-07-25T15:54:57.571+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:57.571+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T15:54:57.571+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:57.571+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T15:54:57.572+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:57.572+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T15:54:57.572+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:57.572+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T15:54:57.573+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:57.573+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T15:54:57.574+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:54:57.574+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T15:54:59.824+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 16.840 seconds
[2025-07-25T15:58:30.955+0700] {processor.py:161} INFO - Started process (PID=8895) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:58:30.956+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T15:58:30.957+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:58:30.956+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:58:30.968+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:58:33.355+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:58:33.354+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T15:58:33.499+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:58:33.499+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T15:58:33.544+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:58:33.544+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T15:58:33.585+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:58:33.585+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T15:58:33.627+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:58:33.627+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T15:58:33.668+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:58:33.668+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T15:58:33.709+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:58:33.709+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T15:58:35.094+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 4.142 seconds
[2025-07-25T15:59:44.262+0700] {processor.py:161} INFO - Started process (PID=9152) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:59:44.263+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T15:59:44.263+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:59:44.263+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:59:44.275+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T15:59:46.100+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:59:46.100+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T15:59:46.293+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:59:46.293+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T15:59:46.337+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:59:46.337+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T15:59:46.381+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:59:46.381+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T15:59:46.424+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:59:46.424+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T15:59:46.471+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:59:46.470+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T15:59:46.515+0700] {logging_mixin.py:188} INFO - [2025-07-25T15:59:46.515+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T15:59:48.103+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 3.844 seconds
[2025-07-25T16:02:48.197+0700] {processor.py:161} INFO - Started process (PID=9600) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:02:48.198+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:02:48.199+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:02:48.199+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:02:48.209+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:02:49.807+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:02:49.807+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:02:49.954+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:02:49.954+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:02:50.001+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:02:50.001+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:02:50.048+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:02:50.048+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:02:50.091+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:02:50.091+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:02:50.135+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:02:50.135+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:02:50.185+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:02:50.185+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:02:51.683+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 3.489 seconds
[2025-07-25T16:04:02.195+0700] {processor.py:161} INFO - Started process (PID=9896) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:04:02.197+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:04:02.198+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:04:02.197+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:04:02.207+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_produces_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:04:03.721+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:04:03.720+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:04:03.876+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:04:03.876+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:04:03.919+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:04:03.919+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:04:03.962+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:04:03.962+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:04:04.004+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:04:04.004+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:04:04.053+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:04:04.052+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:04:04.094+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:04:04.093+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:04:05.594+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 3.402 seconds
[2025-07-25T16:05:40.937+0700] {processor.py:161} INFO - Started process (PID=10238) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:05:40.938+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:05:40.939+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:05:40.939+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:05:40.947+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:05:42.881+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:05:42.881+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:05:43.071+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:05:43.071+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:05:43.126+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:05:43.126+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:05:43.182+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:05:43.181+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:05:43.233+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:05:43.233+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:05:43.285+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:05:43.285+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:05:43.341+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:05:43.340+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:05:45.332+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 4.398 seconds
[2025-07-25T16:07:16.471+0700] {processor.py:161} INFO - Started process (PID=10535) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:07:16.472+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:07:16.473+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:07:16.473+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:07:16.483+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:07:20.280+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:07:20.280+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:07:20.598+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:07:20.598+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:07:20.685+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:07:20.685+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:07:20.775+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:07:20.775+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:07:20.875+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:07:20.875+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:07:20.983+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:07:20.983+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:07:21.089+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:07:21.088+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:07:26.521+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 7.397 seconds
[2025-07-25T16:08:56.193+0700] {processor.py:161} INFO - Started process (PID=10857) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:08:56.194+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:08:56.194+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:08:56.194+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:08:56.203+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:08:57.644+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:08:57.644+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:08:57.784+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:08:57.784+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:08:58.055+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:08:58.055+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:08:58.095+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:08:58.094+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:08:58.135+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:08:58.134+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:08:58.179+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:08:58.179+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:08:58.219+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:08:58.218+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:08:59.555+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 3.365 seconds
[2025-07-25T16:10:27.602+0700] {processor.py:161} INFO - Started process (PID=11320) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:10:27.605+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:10:27.606+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:10:27.606+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:10:27.673+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:10:29.621+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:10:29.621+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:10:29.824+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:10:29.824+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:10:29.883+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:10:29.883+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:10:29.938+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:10:29.938+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:10:30.002+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:10:30.002+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:10:30.061+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:10:30.060+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:10:30.114+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:10:30.114+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:10:32.836+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 5.254 seconds
[2025-07-25T16:10:34.841+0700] {processor.py:161} INFO - Started process (PID=11346) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:10:34.842+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:10:34.842+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:10:34.842+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:10:34.854+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:10:36.768+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:10:36.768+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:10:36.988+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:10:36.987+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:10:37.054+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:10:37.054+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:10:37.132+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:10:37.132+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:10:37.192+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:10:37.192+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:10:37.256+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:10:37.256+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:10:37.313+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:10:37.312+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:10:39.814+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 4.977 seconds
[2025-07-25T16:11:47.070+0700] {processor.py:161} INFO - Started process (PID=11630) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:11:47.073+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:11:47.074+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:11:47.074+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:11:47.093+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:11:53.770+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:11:53.770+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:11:53.952+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:11:53.952+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:11:54.009+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:11:54.009+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:11:54.064+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:11:54.063+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:11:54.119+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:11:54.119+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:11:54.176+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:11:54.176+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:11:54.233+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:11:54.233+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:11:56.158+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 9.092 seconds
[2025-07-25T16:12:09.204+0700] {processor.py:161} INFO - Started process (PID=11669) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:12:09.204+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:12:09.205+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:12:09.205+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:12:09.220+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_produces_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:12:10.496+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:12:10.496+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:12:10.668+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:12:10.668+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:12:10.712+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:12:10.712+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:12:10.758+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:12:10.758+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:12:10.798+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:12:10.798+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:12:10.847+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:12:10.847+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:12:10.889+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:12:10.889+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:12:12.558+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 3.358 seconds
[2025-07-25T16:13:38.100+0700] {processor.py:161} INFO - Started process (PID=11958) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:13:38.107+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:13:38.109+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:13:38.108+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:13:38.152+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:13:38.349+0700] {processor.py:161} INFO - Started process (PID=11960) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:13:38.350+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:13:38.351+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:13:38.350+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:13:38.374+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:13:40.023+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:13:40.022+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:13:40.305+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:13:40.304+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:13:40.398+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:13:40.398+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:13:40.441+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:13:40.441+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:13:40.488+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:13:40.488+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:13:40.587+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:13:40.586+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:13:40.677+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:13:40.676+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:13:41.738+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:13:41.737+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:13:41.896+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:13:41.896+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:13:41.943+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:13:41.942+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:13:41.988+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:13:41.988+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:13:42.034+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:13:42.034+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:13:42.088+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:13:42.087+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:13:42.132+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:13:42.131+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:13:42.178+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 4.114 seconds
[2025-07-25T16:13:43.783+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 5.438 seconds
[2025-07-25T16:15:21.501+0700] {processor.py:161} INFO - Started process (PID=12127) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:15:21.502+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:15:21.503+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:21.503+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:15:21.514+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:15:21.677+0700] {processor.py:161} INFO - Started process (PID=12128) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:15:21.678+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:15:21.679+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:21.678+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:15:21.687+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:15:24.980+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:24.980+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:15:24.999+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:24.998+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:15:25.140+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:25.139+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:15:25.186+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:25.185+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:15:25.228+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:25.228+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:15:25.271+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:25.270+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:15:25.316+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:25.316+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:15:25.362+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:25.362+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:15:26.406+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:26.405+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:15:26.449+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:26.449+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:15:26.493+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:26.493+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:15:26.535+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:26.534+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:15:26.581+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:26.580+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:15:26.621+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:26.620+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:15:26.899+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 5.400 seconds
[2025-07-25T16:15:28.054+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:28.052+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_produces_2) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_produces_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1193 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 22, 828237, tzinfo=Timezone('UTC')), 'dag_hash': '3e73deed92cfbed54c89c508c36882ac', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 23, 463274, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 23, 954317, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 24, 544428, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:15:28.055+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:28.055+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_produces_2) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_produces_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1193 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 22, 828237, tzinfo=Timezone('UTC')), 'dag_hash': '3e73deed92cfbed54c89c508c36882ac', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 23, 463274, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 23, 954317, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 24, 544428, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:15:28.056+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:28.056+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_produces_2) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_produces_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1193 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 22, 828237, tzinfo=Timezone('UTC')), 'dag_hash': '3e73deed92cfbed54c89c508c36882ac', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 23, 463274, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 23, 954317, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 24, 544428, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:15:28.057+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:28.057+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_produces_2) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_produces_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1193 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 22, 828237, tzinfo=Timezone('UTC')), 'dag_hash': '3e73deed92cfbed54c89c508c36882ac', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 23, 463274, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 23, 954317, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 24, 544428, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:15:28.058+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:28.058+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_produces_2) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_produces_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1193 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 22, 828237, tzinfo=Timezone('UTC')), 'dag_hash': '3e73deed92cfbed54c89c508c36882ac', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 23, 463274, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 23, 954317, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 24, 544428, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:15:28.059+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:28.058+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_produces_2) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_produces_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1193 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 22, 828237, tzinfo=Timezone('UTC')), 'dag_hash': '3e73deed92cfbed54c89c508c36882ac', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 23, 463274, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 23, 954317, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 24, 544428, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:15:28.059+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:15:28.059+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:15:28.059+0700] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 859, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 895, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/tenacity/__init__.py", line 314, in iter
    return fut.result()
           ^^^^^^^^^^^^
  File "/usr/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 673, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dag.py", line 3048, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_produces_2) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_produces_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1193 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 22, 828237, tzinfo=Timezone('UTC')), 'dag_hash': '3e73deed92cfbed54c89c508c36882ac', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 23, 463274, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 23, 954317, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 15, 24, 544428, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:16:46.941+0700] {processor.py:161} INFO - Started process (PID=12295) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:16:46.942+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:16:46.943+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:46.942+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:16:46.950+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:16:51.962+0700] {processor.py:161} INFO - Started process (PID=12299) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:16:51.963+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:16:51.964+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:51.964+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:16:51.971+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_produces_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:16:52.766+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:52.766+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:16:52.966+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:52.966+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:16:53.030+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:53.029+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:16:53.089+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:53.089+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:16:53.149+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:53.148+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:16:53.209+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:53.209+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:16:53.272+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:53.272+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:16:55.157+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:55.156+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:16:55.366+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:55.366+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:16:55.413+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 8.475 seconds
[2025-07-25T16:16:55.432+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:55.432+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:16:55.494+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:55.494+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:16:55.555+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:55.555+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:16:55.621+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:55.620+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:16:55.684+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:55.684+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:16:57.546+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:57.544+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_1) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "_dag_id": "dataset_consumes_1", "_task_group": {"_group_id": null, "prefix_group ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 16, 53, 348246, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "_dag_id": "dataset_consumes_1_never_scheduled", "_task_group": {"_group_id": nul ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 16, 54, 159776, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:16:57.547+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:57.546+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_1) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "_dag_id": "dataset_consumes_1", "_task_group": {"_group_id": null, "prefix_group ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 16, 53, 348246, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "_dag_id": "dataset_consumes_1_never_scheduled", "_task_group": {"_group_id": nul ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 16, 54, 159776, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:16:57.547+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:57.547+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_1) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "_dag_id": "dataset_consumes_1", "_task_group": {"_group_id": null, "prefix_group ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 16, 53, 348246, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "_dag_id": "dataset_consumes_1_never_scheduled", "_task_group": {"_group_id": nul ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 16, 54, 159776, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:16:57.548+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:57.548+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_1) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "_dag_id": "dataset_consumes_1", "_task_group": {"_group_id": null, "prefix_group ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 16, 53, 348246, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "_dag_id": "dataset_consumes_1_never_scheduled", "_task_group": {"_group_id": nul ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 16, 54, 159776, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:16:57.550+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:57.549+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_1) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "_dag_id": "dataset_consumes_1", "_task_group": {"_group_id": null, "prefix_group ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 16, 53, 348246, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "_dag_id": "dataset_consumes_1_never_scheduled", "_task_group": {"_group_id": nul ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 16, 54, 159776, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:16:57.551+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:57.550+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_1) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "_dag_id": "dataset_consumes_1", "_task_group": {"_group_id": null, "prefix_group ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 16, 53, 348246, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "_dag_id": "dataset_consumes_1_never_scheduled", "_task_group": {"_group_id": nul ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 16, 54, 159776, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:16:57.551+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:16:57.551+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:16:57.552+0700] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 859, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 895, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/tenacity/__init__.py", line 314, in iter
    return fut.result()
           ^^^^^^^^^^^^
  File "/usr/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 673, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dag.py", line 3048, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_1) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "_dag_id": "dataset_consumes_1", "_task_group": {"_group_id": null, "prefix_group ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 16, 53, 348246, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"tags": ["consumes", "dataset-scheduled"], "_dag_id": "dataset_consumes_1_never_scheduled", "_task_group": {"_group_id": nul ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 16, 54, 159776, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:18:34.824+0700] {processor.py:161} INFO - Started process (PID=12484) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:18:34.826+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:18:34.827+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:18:34.827+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:18:34.839+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_produces_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:18:36.405+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:18:36.404+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:18:36.560+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:18:36.560+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:18:36.603+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:18:36.603+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:18:36.646+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:18:36.646+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:18:36.692+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:18:36.692+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:18:36.741+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:18:36.741+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:18:36.792+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:18:36.792+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:18:38.290+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 3.469 seconds
[2025-07-25T16:18:38.938+0700] {processor.py:161} INFO - Started process (PID=12491) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:18:38.941+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:18:38.942+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:18:38.942+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:18:38.952+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:18:43.788+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:18:43.788+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:18:43.942+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:18:43.942+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:18:43.988+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:18:43.988+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:18:44.033+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:18:44.032+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:18:44.075+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:18:44.074+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:18:44.120+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:18:44.119+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:18:44.163+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:18:44.163+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:18:45.894+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 6.961 seconds
[2025-07-25T16:20:09.593+0700] {processor.py:161} INFO - Started process (PID=12647) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:20:09.595+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:20:09.595+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:20:09.595+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:20:09.603+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:20:11.270+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:20:11.270+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:20:11.458+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:20:11.458+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:20:11.506+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:20:11.506+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:20:11.525+0700] {processor.py:161} INFO - Started process (PID=12649) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:20:11.526+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:20:11.527+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:20:11.526+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:20:11.534+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:20:11.551+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:20:11.550+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:20:11.599+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:20:11.599+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:20:11.646+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:20:11.646+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:20:11.698+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:20:11.697+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:20:13.215+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:20:13.214+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:20:13.363+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:20:13.362+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:20:13.399+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 3.809 seconds
[2025-07-25T16:20:13.410+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:20:13.409+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:20:13.453+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:20:13.452+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:20:13.496+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:20:13.496+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:20:13.544+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:20:13.544+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:20:13.585+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:20:13.585+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:20:14.980+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 3.457 seconds
[2025-07-25T16:21:39.977+0700] {processor.py:161} INFO - Started process (PID=12818) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:21:39.978+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:21:39.979+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:21:39.979+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:21:39.987+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:21:42.736+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:21:42.736+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:21:42.925+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:21:42.925+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:21:42.982+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:21:42.982+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:21:43.039+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:21:43.038+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:21:43.093+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:21:43.093+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:21:43.152+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:21:43.152+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:21:43.213+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:21:43.213+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:21:43.572+0700] {processor.py:161} INFO - Started process (PID=12822) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:21:43.573+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:21:43.573+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:21:43.573+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:21:43.581+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:21:45.039+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 5.066 seconds
[2025-07-25T16:21:45.628+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:21:45.628+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:21:45.835+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:21:45.834+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:21:45.897+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:21:45.897+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:21:45.958+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:21:45.958+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:21:46.020+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:21:46.019+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:21:46.089+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:21:46.089+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:21:46.153+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:21:46.153+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:21:48.190+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 4.621 seconds
[2025-07-25T16:23:28.810+0700] {processor.py:161} INFO - Started process (PID=13003) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:23:28.811+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:23:28.812+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:28.812+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:23:28.820+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:23:29.144+0700] {processor.py:161} INFO - Started process (PID=13004) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:23:29.144+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:23:29.145+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:29.145+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:23:29.154+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:23:37.446+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:37.446+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:23:37.641+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:37.640+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:23:37.698+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:37.698+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:23:37.735+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:37.735+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:23:37.750+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:37.749+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:23:37.802+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:37.802+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:23:37.859+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:37.859+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:23:37.916+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:37.915+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:23:39.224+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:39.223+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:23:39.282+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:39.282+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:23:39.338+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:39.337+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:23:39.397+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:39.397+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:23:39.456+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:39.455+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:23:39.511+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:39.511+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:23:39.797+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 8.293 seconds
[2025-07-25T16:23:40.939+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:40.937+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_produces_2) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_produces_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1193 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 30, 789770, tzinfo=Timezone('UTC')), 'dag_hash': '3e73deed92cfbed54c89c508c36882ac', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 31, 811204, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_produces_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1197 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 32, 565456, tzinfo=Timezone('UTC')), 'dag_hash': '73902e5ea831c527ec40be15af2e3b87', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 33, 288914, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 34, 9405, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 37, 38480, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:23:40.942+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:40.941+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_produces_2) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_produces_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1193 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 30, 789770, tzinfo=Timezone('UTC')), 'dag_hash': '3e73deed92cfbed54c89c508c36882ac', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 31, 811204, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_produces_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1197 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 32, 565456, tzinfo=Timezone('UTC')), 'dag_hash': '73902e5ea831c527ec40be15af2e3b87', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 33, 288914, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 34, 9405, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 37, 38480, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:23:40.944+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:40.943+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_produces_2) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_produces_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1193 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 30, 789770, tzinfo=Timezone('UTC')), 'dag_hash': '3e73deed92cfbed54c89c508c36882ac', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 31, 811204, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_produces_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1197 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 32, 565456, tzinfo=Timezone('UTC')), 'dag_hash': '73902e5ea831c527ec40be15af2e3b87', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 33, 288914, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 34, 9405, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 37, 38480, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:23:40.945+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:40.944+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_produces_2) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_produces_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1193 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 30, 789770, tzinfo=Timezone('UTC')), 'dag_hash': '3e73deed92cfbed54c89c508c36882ac', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 31, 811204, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_produces_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1197 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 32, 565456, tzinfo=Timezone('UTC')), 'dag_hash': '73902e5ea831c527ec40be15af2e3b87', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 33, 288914, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 34, 9405, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 37, 38480, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:23:40.945+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:40.945+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_produces_2) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_produces_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1193 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 30, 789770, tzinfo=Timezone('UTC')), 'dag_hash': '3e73deed92cfbed54c89c508c36882ac', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 31, 811204, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_produces_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1197 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 32, 565456, tzinfo=Timezone('UTC')), 'dag_hash': '73902e5ea831c527ec40be15af2e3b87', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 33, 288914, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 34, 9405, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 37, 38480, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:23:40.946+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:40.946+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_produces_2) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_produces_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1193 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 30, 789770, tzinfo=Timezone('UTC')), 'dag_hash': '3e73deed92cfbed54c89c508c36882ac', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 31, 811204, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_produces_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1197 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 32, 565456, tzinfo=Timezone('UTC')), 'dag_hash': '73902e5ea831c527ec40be15af2e3b87', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 33, 288914, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 34, 9405, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 37, 38480, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:23:40.946+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:23:40.946+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:23:40.947+0700] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 859, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 895, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/tenacity/__init__.py", line 314, in iter
    return fut.result()
           ^^^^^^^^^^^^
  File "/usr/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 673, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dag.py", line 3048, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_produces_2) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_produces_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1193 characters truncated) ... es": [{"source": "dataset_produces_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag2/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 30, 789770, tzinfo=Timezone('UTC')), 'dag_hash': '3e73deed92cfbed54c89c508c36882ac', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 31, 811204, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_produces_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1197 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 32, 565456, tzinfo=Timezone('UTC')), 'dag_hash': '73902e5ea831c527ec40be15af2e3b87', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 33, 288914, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 34, 9405, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 23, 37, 38480, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:25:49.963+0700] {processor.py:161} INFO - Started process (PID=13215) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:25:49.964+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:25:49.965+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:25:49.964+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:25:49.974+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:25:50.017+0700] {processor.py:161} INFO - Started process (PID=13217) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:25:50.018+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:25:50.019+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:25:50.018+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:25:50.026+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:25:52.694+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:25:52.694+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:25:52.756+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:25:52.755+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:25:52.921+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:25:52.920+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:25:52.979+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:25:52.978+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:25:53.034+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:25:53.034+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:25:53.088+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:25:53.087+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:25:53.145+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:25:53.144+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:25:53.200+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:25:53.199+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:25:54.440+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:25:54.439+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:25:54.495+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:25:54.495+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:25:54.550+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:25:54.550+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:25:54.604+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:25:54.604+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:25:54.661+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:25:54.660+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:25:54.712+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:25:54.712+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:25:55.031+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 5.017 seconds
[2025-07-25T16:25:56.594+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 6.634 seconds
[2025-07-25T16:27:48.901+0700] {processor.py:161} INFO - Started process (PID=13388) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:27:48.902+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:27:48.903+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:27:48.903+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:27:48.913+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:27:49.917+0700] {processor.py:161} INFO - Started process (PID=13390) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:27:49.918+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:27:49.918+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:27:49.918+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:27:49.926+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:27:55.447+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:27:55.447+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:27:57.713+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:27:57.713+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:27:57.771+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:27:57.771+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:27:57.829+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:27:57.829+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:27:57.886+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:27:57.886+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:27:57.942+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:27:57.942+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:27:58.001+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:27:58.000+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:27:59.865+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:27:59.865+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:28:00.030+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 9.054 seconds
[2025-07-25T16:28:00.071+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:28:00.071+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:28:00.140+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:28:00.140+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:28:00.201+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:28:00.200+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:28:00.261+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:28:00.261+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:28:00.325+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:28:00.325+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:28:00.478+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:28:00.477+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:28:02.433+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:28:02.431+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_1) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 52, 327745, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 53, 803315, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_produces_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1197 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 55, 125215, tzinfo=Timezone('UTC')), 'dag_hash': '73902e5ea831c527ec40be15af2e3b87', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 58, 103158, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:28:02.434+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:28:02.434+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_1) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 52, 327745, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 53, 803315, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_produces_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1197 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 55, 125215, tzinfo=Timezone('UTC')), 'dag_hash': '73902e5ea831c527ec40be15af2e3b87', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 58, 103158, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:28:02.435+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:28:02.435+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_1) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 52, 327745, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 53, 803315, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_produces_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1197 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 55, 125215, tzinfo=Timezone('UTC')), 'dag_hash': '73902e5ea831c527ec40be15af2e3b87', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 58, 103158, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:28:02.436+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:28:02.436+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_1) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 52, 327745, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 53, 803315, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_produces_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1197 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 55, 125215, tzinfo=Timezone('UTC')), 'dag_hash': '73902e5ea831c527ec40be15af2e3b87', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 58, 103158, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:28:02.437+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:28:02.437+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_1) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 52, 327745, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 53, 803315, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_produces_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1197 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 55, 125215, tzinfo=Timezone('UTC')), 'dag_hash': '73902e5ea831c527ec40be15af2e3b87', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 58, 103158, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:28:02.438+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:28:02.437+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_1) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 52, 327745, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 53, 803315, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_produces_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1197 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 55, 125215, tzinfo=Timezone('UTC')), 'dag_hash': '73902e5ea831c527ec40be15af2e3b87', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 58, 103158, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:28:02.438+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:28:02.438+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:28:02.439+0700] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 859, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 895, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/tenacity/__init__.py", line 314, in iter
    return fut.result()
           ^^^^^^^^^^^^
  File "/usr/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 673, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dag.py", line 3048, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_1) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1486 characters truncated) ... "dataset_consumes_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_1_task/dataset_other.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 52, 327745, tzinfo=Timezone('UTC')), 'dag_hash': 'e7b43c60c43bf781ef02d6ac10932578', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_and_2', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1745 characters truncated) ... mes_1_and_2", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 53, 803315, tzinfo=Timezone('UTC')), 'dag_hash': '9b6fb08ed1f81ebc10ca1423e13cefd2', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_produces_1', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1197 characters truncated) ... es": [{"source": "dataset_produces_1", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://dag1/output_1.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 55, 125215, tzinfo=Timezone('UTC')), 'dag_hash': '73902e5ea831c527ec40be15af2e3b87', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 27, 58, 103158, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:29:59.332+0700] {processor.py:161} INFO - Started process (PID=13587) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:29:59.334+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:29:59.335+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:29:59.334+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:29:59.349+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:30:03.142+0700] {processor.py:161} INFO - Started process (PID=13595) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:30:03.145+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:30:03.146+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:03.146+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:30:03.156+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:30:03.680+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:03.680+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:30:03.878+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:03.878+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:30:03.928+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:03.928+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:30:03.981+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:03.981+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:30:04.027+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:04.027+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:30:04.070+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:04.069+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:30:04.114+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:04.114+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:30:05.473+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:05.472+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:30:05.616+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 6.288 seconds
[2025-07-25T16:30:05.623+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:05.623+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:30:05.665+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:05.665+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:30:05.708+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:05.708+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:30:05.762+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:05.762+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:30:05.810+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:05.810+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:30:05.855+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:05.855+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:30:07.083+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:07.082+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_unknown_never_scheduled) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 30, 4, 242434, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 30, 4, 812711, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:30:07.084+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:07.084+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_unknown_never_scheduled) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 30, 4, 242434, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 30, 4, 812711, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:30:07.085+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:07.085+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_unknown_never_scheduled) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 30, 4, 242434, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 30, 4, 812711, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:30:07.086+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:07.086+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_unknown_never_scheduled) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 30, 4, 242434, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 30, 4, 812711, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:30:07.087+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:07.086+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_unknown_never_scheduled) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 30, 4, 242434, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 30, 4, 812711, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:30:07.087+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:07.087+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_unknown_never_scheduled) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 30, 4, 242434, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 30, 4, 812711, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:30:07.088+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:30:07.088+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:30:07.088+0700] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 859, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 895, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/tenacity/__init__.py", line 314, in iter
    return fut.result()
           ^^^^^^^^^^^^
  File "/usr/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 673, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dag.py", line 3048, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_unknown_never_scheduled) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: ({'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 30, 4, 242434, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}, {'dag_id': 'dataset_consumes_1_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1808 characters truncated) ... r_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://consuming_2_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 30, 4, 812711, tzinfo=Timezone('UTC')), 'dag_hash': '7dfd7299beb42bfb7d0f2bf8bdbc2251', 'processor_subdir': '/home/ngtph/airflow/dags'})]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:31:56.898+0700] {processor.py:161} INFO - Started process (PID=13757) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:31:56.900+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:31:56.900+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:31:56.900+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:31:56.909+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:32:05.597+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:32:05.597+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:32:05.786+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:32:05.785+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:32:05.857+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:32:05.856+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:32:05.930+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:32:05.930+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:32:05.987+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:32:05.986+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:32:06.042+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:32:06.042+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:32:06.106+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:32:06.106+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:32:07.854+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 8.035 seconds
[2025-07-25T16:32:08.704+0700] {processor.py:161} INFO - Started process (PID=13766) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:32:08.705+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:32:08.706+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:32:08.706+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:32:08.714+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:32:10.211+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:32:10.211+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:32:10.426+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:32:10.426+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:32:10.491+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:32:10.491+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:32:10.570+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:32:10.570+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:32:10.625+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:32:10.625+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:32:10.764+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:32:10.764+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:32:10.816+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:32:10.815+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:32:12.738+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 4.037 seconds
[2025-07-25T16:33:53.629+0700] {processor.py:161} INFO - Started process (PID=13939) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:33:53.630+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:33:53.631+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:33:53.631+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:33:53.638+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:33:58.042+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:33:58.041+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:33:58.193+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:33:58.192+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:33:58.237+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:33:58.237+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:33:58.282+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:33:58.282+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:33:58.328+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:33:58.328+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:33:58.374+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:33:58.373+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:33:58.422+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:33:58.422+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:33:59.411+0700] {processor.py:161} INFO - Started process (PID=13950) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:33:59.412+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:33:59.413+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:33:59.413+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:33:59.421+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:34:00.063+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 6.437 seconds
[2025-07-25T16:34:00.705+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:34:00.704+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:34:00.862+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:34:00.862+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:34:00.907+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:34:00.907+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:34:00.955+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:34:00.955+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:34:01.009+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:34:01.009+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:34:01.057+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:34:01.056+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:34:01.103+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:34:01.103+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:34:02.774+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 3.367 seconds
[2025-07-25T16:35:26.191+0700] {processor.py:161} INFO - Started process (PID=14087) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:35:26.194+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:35:26.195+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:35:26.195+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:35:26.203+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:35:28.824+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:35:28.824+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:35:28.989+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:35:28.989+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:35:29.120+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:35:29.120+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:35:29.221+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:35:29.220+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:35:29.306+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:35:29.305+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:35:29.401+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:35:29.401+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:35:29.492+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:35:29.492+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:35:31.455+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 5.267 seconds
[2025-07-25T16:35:37.097+0700] {processor.py:161} INFO - Started process (PID=14110) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:35:37.098+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:35:37.099+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:35:37.099+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:35:37.108+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:35:39.048+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:35:39.048+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:35:39.236+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:35:39.236+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:35:39.294+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:35:39.294+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:35:39.350+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:35:39.350+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:35:39.406+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:35:39.406+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:35:39.464+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:35:39.464+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:35:39.521+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:35:39.521+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:35:41.980+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 4.887 seconds
[2025-07-25T16:37:00.739+0700] {processor.py:161} INFO - Started process (PID=14256) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:37:00.742+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:37:00.742+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:00.742+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:37:00.751+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_produces_2' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:37:05.238+0700] {processor.py:161} INFO - Started process (PID=14259) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:37:05.241+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:37:05.241+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:05.241+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:37:05.249+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:37:05.855+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:05.855+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:37:06.048+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:06.048+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:37:06.101+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:06.101+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:37:06.152+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:06.152+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:37:06.202+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:06.202+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:37:06.252+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:06.251+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:37:06.298+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:06.298+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:37:08.151+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 7.416 seconds
[2025-07-25T16:37:08.354+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:08.354+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:37:08.558+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:08.557+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:37:08.621+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:08.621+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:37:08.683+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:08.683+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:37:08.741+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:08.741+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:37:08.803+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:08.803+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:37:08.863+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:08.862+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:37:10.687+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:10.684+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_unknown_never_scheduled) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 37, 6, 526105, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:37:10.689+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:10.689+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_unknown_never_scheduled) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 37, 6, 526105, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:37:10.690+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:10.690+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_unknown_never_scheduled) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 37, 6, 526105, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:37:10.691+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:10.691+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_unknown_never_scheduled) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 37, 6, 526105, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:37:10.694+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:10.694+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_unknown_never_scheduled) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 37, 6, 526105, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:37:10.695+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:10.695+0700] {dagbag.py:647} ERROR - Failed to write serialized DAG: /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
       ^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_unknown_never_scheduled) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 37, 6, 526105, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:37:10.695+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:37:10.695+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:37:10.696+0700] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 859, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/dag_processing/processor.py", line 895, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/tenacity/__init__.py", line 314, in iter
    return fut.result()
           ^^^^^^^^^^^^
  File "/usr/lib/python3.11/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.11/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 673, in _sync_to_db
    DAG.bulk_write_to_db(dags.values(), processor_subdir=processor_subdir, session=session)
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/models/dag.py", line 3048, in bulk_write_to_db
    orm_dags: list[DagModel] = session.scalars(query).unique().all()
                               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 724, in _connection_for_bind
    self._assert_active()
  File "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/sqlalchemy/orm/session.py", line 604, in _assert_active
    raise sa_exc.PendingRollbackError(
sqlalchemy.exc.PendingRollbackError: This Session's transaction has been rolled back due to a previous exception during flush. To begin a new transaction with this Session, first issue Session.rollback(). Original exception was: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint "serialized_dag_pkey"
DETAIL:  Key (dag_id)=(dataset_consumes_unknown_never_scheduled) already exists.

[SQL: INSERT INTO serialized_dag (dag_id, fileloc, fileloc_hash, data, data_compressed, last_updated, dag_hash, processor_subdir) VALUES (%(dag_id)s, %(fileloc)s, %(fileloc_hash)s, %(data)s, %(data_compressed)s, %(last_updated)s, %(dag_hash)s, %(processor_subdir)s)]
[parameters: {'dag_id': 'dataset_consumes_unknown_never_scheduled', 'fileloc': '/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py', 'fileloc_hash': 10913145856485950, 'data': '{"__version": 1, "dag": {"start_date": 1609459200.0, "fileloc": "/home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/e ... (1830 characters truncated) ... ver_scheduled", "target": "dataset", "dependency_type": "dataset", "dependency_id": "s3://unrelated_task/dataset_other_unknown.txt"}], "params": {}}}', 'data_compressed': None, 'last_updated': datetime.datetime(2025, 7, 25, 9, 37, 6, 526105, tzinfo=Timezone('UTC')), 'dag_hash': '6621c3f56b8ceee2e49b6c5334889ba7', 'processor_subdir': '/home/ngtph/airflow/dags'}]
(Background on this error at: https://sqlalche.me/e/14/gkpj) (Background on this error at: https://sqlalche.me/e/14/7s2a)
[2025-07-25T16:38:41.901+0700] {processor.py:161} INFO - Started process (PID=14414) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:38:41.903+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:38:41.904+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:38:41.904+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:38:41.911+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:38:46.293+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:38:46.293+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:38:46.465+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:38:46.464+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:38:46.511+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:38:46.511+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:38:46.558+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:38:46.558+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:38:46.602+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:38:46.602+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:38:46.646+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:38:46.646+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:38:46.695+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:38:46.694+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:38:48.292+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 6.394 seconds
[2025-07-25T16:38:54.088+0700] {processor.py:161} INFO - Started process (PID=14437) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:38:54.090+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:38:54.090+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:38:54.090+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:38:54.100+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_produces_2' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:38:55.355+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:38:55.355+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:38:55.513+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:38:55.513+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:38:55.558+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:38:55.558+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:38:55.604+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:38:55.604+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:38:55.646+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:38:55.646+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:38:55.695+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:38:55.694+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:38:55.738+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:38:55.738+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:38:57.243+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 3.158 seconds
[2025-07-25T16:40:14.637+0700] {processor.py:161} INFO - Started process (PID=14572) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:40:14.638+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:40:14.639+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:40:14.639+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:40:14.647+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:40:16.084+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:40:16.083+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:40:16.328+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:40:16.328+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:40:16.370+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:40:16.369+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:40:16.410+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:40:16.409+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:40:16.451+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:40:16.451+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:40:16.492+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:40:16.492+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:40:16.535+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:40:16.535+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:40:17.961+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 3.328 seconds
[2025-07-25T16:40:24.920+0700] {processor.py:161} INFO - Started process (PID=14602) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:40:24.923+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:40:24.924+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:40:24.924+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:40:24.932+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:40:26.824+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:40:26.823+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:40:27.018+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:40:27.017+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:40:27.077+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:40:27.077+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:40:27.134+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:40:27.134+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:40:27.193+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:40:27.193+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:40:27.253+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:40:27.253+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:40:27.313+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:40:27.313+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:40:29.248+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 4.330 seconds
[2025-07-25T16:41:44.947+0700] {processor.py:161} INFO - Started process (PID=14728) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:41:44.948+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:41:44.949+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:41:44.948+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:41:44.958+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:41:46.970+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:41:46.970+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:41:47.187+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:41:47.186+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:41:47.251+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:41:47.251+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:41:47.315+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:41:47.315+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:41:47.376+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:41:47.376+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:41:47.441+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:41:47.440+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:41:47.504+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:41:47.503+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:41:49.581+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 4.637 seconds
[2025-07-25T16:41:53.184+0700] {processor.py:161} INFO - Started process (PID=14745) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:41:53.186+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:41:53.187+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:41:53.186+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:41:53.196+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:41:58.328+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:41:58.327+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:41:58.521+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:41:58.521+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:41:58.577+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:41:58.576+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:41:58.632+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:41:58.632+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:41:58.696+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:41:58.696+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:41:58.749+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:41:58.749+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:41:58.802+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:41:58.802+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:42:00.941+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 7.761 seconds
[2025-07-25T16:43:34.187+0700] {processor.py:161} INFO - Started process (PID=14913) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:43:34.188+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:43:34.189+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:43:34.189+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:43:34.198+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:43:36.736+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:43:36.736+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:43:36.913+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:43:36.912+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:43:36.962+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:43:36.961+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:43:37.008+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:43:37.008+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:43:37.067+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:43:37.067+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:43:37.115+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:43:37.114+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:43:37.161+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:43:37.161+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:43:37.621+0700] {processor.py:161} INFO - Started process (PID=14919) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:43:37.622+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:43:37.622+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:43:37.622+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:43:37.633+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:43:38.848+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 4.664 seconds
[2025-07-25T16:43:43.014+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:43:43.014+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:43:43.239+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:43:43.238+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:43:43.302+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:43:43.301+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:43:43.358+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:43:43.358+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:43:43.413+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:43:43.413+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:43:43.468+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:43:43.468+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:43:43.522+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:43:43.522+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:43:45.407+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 7.789 seconds
[2025-07-25T16:45:15.201+0700] {processor.py:161} INFO - Started process (PID=15091) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:45:15.203+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:45:15.204+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:45:15.203+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:45:15.215+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:45:18.015+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:45:18.015+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:45:18.206+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:45:18.205+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:45:18.256+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:45:18.255+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:45:18.306+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:45:18.306+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:45:18.355+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:45:18.355+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:45:18.407+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:45:18.407+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:45:18.456+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:45:18.456+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:45:20.167+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 4.971 seconds
[2025-07-25T16:46:58.875+0700] {processor.py:161} INFO - Started process (PID=15194) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:46:58.877+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:46:58.878+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:46:58.877+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:46:58.891+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:47:05.465+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:47:05.464+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:47:05.715+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:47:05.715+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:47:05.801+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:47:05.800+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:47:05.875+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:47:05.874+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:47:05.945+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:47:05.944+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:47:06.010+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:47:06.009+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:47:06.092+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:47:06.092+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:47:08.662+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 9.791 seconds
[2025-07-25T16:49:48.367+0700] {processor.py:161} INFO - Started process (PID=15333) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:49:48.370+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:49:48.372+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:49:48.371+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:49:48.397+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:49:57.537+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:49:57.536+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:49:57.723+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:49:57.723+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:49:57.775+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:49:57.774+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:49:57.824+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:49:57.823+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:49:57.873+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:49:57.872+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:49:57.922+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:49:57.922+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:49:57.969+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:49:57.969+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:50:00.492+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 9.720 seconds
[2025-07-25T16:52:26.395+0700] {processor.py:161} INFO - Started process (PID=15465) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:52:26.397+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:52:26.398+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:52:26.397+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:52:26.411+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_and_2', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:52:38.963+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:52:38.962+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:52:39.590+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:52:39.589+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:52:39.773+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:52:39.772+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:52:39.872+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:52:39.872+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:52:39.972+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:52:39.972+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:52:40.139+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:52:40.139+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:52:40.326+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:52:40.326+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:52:43.431+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 17.040 seconds
[2025-07-25T16:55:00.478+0700] {processor.py:161} INFO - Started process (PID=15592) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:55:00.482+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:55:00.483+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:55:00.483+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:55:00.503+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_1', 'dataset_produces_1', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_2' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:55:11.057+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:55:11.057+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:55:11.357+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:55:11.356+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:55:11.466+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:55:11.466+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:55:11.602+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:55:11.602+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:55:11.706+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:55:11.705+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:55:11.800+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:55:11.799+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:55:11.891+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:55:11.891+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:55:14.612+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 11.509 seconds
[2025-07-25T16:57:07.957+0700] {processor.py:161} INFO - Started process (PID=15749) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:57:07.960+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:57:07.962+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:57:07.961+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:57:07.982+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1', 'dataset_produces_2', 'dataset_produces_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:57:14.158+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:57:14.157+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:57:14.369+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:57:14.369+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:57:14.429+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:57:14.428+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:57:14.488+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:57:14.488+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:57:14.549+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:57:14.548+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:57:14.612+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:57:14.611+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:57:14.678+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:57:14.677+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:57:16.770+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 8.822 seconds
[2025-07-25T16:59:22.143+0700] {processor.py:161} INFO - Started process (PID=15911) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:59:22.146+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T16:59:22.148+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:59:22.147+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:59:22.174+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T16:59:28.056+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:59:28.056+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T16:59:28.237+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:59:28.237+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T16:59:28.289+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:59:28.289+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T16:59:28.337+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:59:28.336+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T16:59:28.386+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:59:28.385+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T16:59:28.434+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:59:28.434+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T16:59:28.483+0700] {logging_mixin.py:188} INFO - [2025-07-25T16:59:28.483+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T16:59:30.168+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 8.033 seconds
[2025-07-25T17:01:15.166+0700] {processor.py:161} INFO - Started process (PID=16043) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T17:01:15.169+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T17:01:15.172+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:01:15.171+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T17:01:15.194+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T17:01:16.657+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:01:16.656+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T17:01:16.827+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:01:16.827+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T17:01:16.877+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:01:16.877+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T17:01:16.925+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:01:16.925+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T17:01:16.967+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:01:16.966+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T17:01:17.012+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:01:17.011+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T17:01:17.060+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:01:17.060+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T17:01:18.511+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 3.352 seconds
[2025-07-25T17:03:08.493+0700] {processor.py:161} INFO - Started process (PID=16147) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T17:03:08.495+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T17:03:08.497+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:03:08.496+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T17:03:08.528+0700] {processor.py:840} INFO - DAG(s) 'dataset_produces_1', 'dataset_consumes_1_and_2', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1', 'dataset_consumes_unknown_never_scheduled' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T17:03:14.649+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:03:14.648+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T17:03:14.884+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:03:14.884+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T17:03:14.950+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:03:14.950+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T17:03:15.013+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:03:15.012+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T17:03:15.099+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:03:15.098+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T17:03:15.165+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:03:15.164+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T17:03:15.251+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:03:15.250+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T17:03:17.828+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 9.345 seconds
[2025-07-25T17:05:31.045+0700] {processor.py:161} INFO - Started process (PID=16312) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T17:05:31.048+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T17:05:31.050+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:05:31.049+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T17:05:31.075+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1', 'dataset_produces_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_and_2', 'dataset_produces_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T17:05:36.572+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:05:36.571+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T17:05:36.773+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:05:36.773+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T17:05:36.825+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:05:36.824+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T17:05:36.871+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:05:36.871+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T17:05:36.918+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:05:36.917+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T17:05:36.967+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:05:36.967+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T17:05:37.011+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:05:37.010+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T17:05:38.586+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 7.553 seconds
[2025-07-25T17:06:53.899+0700] {processor.py:161} INFO - Started process (PID=16390) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T17:06:53.902+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T17:06:53.903+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:06:53.903+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T17:06:53.926+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_produces_2', 'dataset_consumes_1_and_2', 'dataset_consumes_1_never_scheduled', 'dataset_consumes_1' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T17:06:59.181+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:06:59.181+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T17:06:59.432+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:06:59.432+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T17:06:59.531+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:06:59.531+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T17:06:59.614+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:06:59.614+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T17:06:59.672+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:06:59.672+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T17:06:59.807+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:06:59.806+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T17:06:59.891+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:06:59.891+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T17:07:02.163+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 8.273 seconds
[2025-07-25T17:08:21.757+0700] {processor.py:161} INFO - Started process (PID=16477) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T17:08:21.760+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T17:08:21.763+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:08:21.761+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T17:08:21.783+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1_never_scheduled', 'dataset_produces_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_produces_1', 'dataset_consumes_1', 'dataset_consumes_1_and_2' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T17:08:23.623+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:08:23.623+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T17:08:23.829+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:08:23.829+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T17:08:23.887+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:08:23.886+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T17:08:23.939+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:08:23.939+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T17:08:23.997+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:08:23.997+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T17:08:24.057+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:08:24.056+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T17:08:24.109+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:08:24.108+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T17:08:26.005+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 4.259 seconds
[2025-07-25T17:10:35.800+0700] {processor.py:161} INFO - Started process (PID=16621) to work on /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T17:10:35.802+0700] {processor.py:830} INFO - Processing file /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py for tasks to queue
[2025-07-25T17:10:35.804+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:10:35.803+0700] {dagbag.py:538} INFO - Filling up the DagBag from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T17:10:35.823+0700] {processor.py:840} INFO - DAG(s) 'dataset_consumes_1', 'dataset_consumes_1_and_2', 'dataset_consumes_unknown_never_scheduled', 'dataset_consumes_1_never_scheduled', 'dataset_produces_1', 'dataset_produces_2' retrieved from /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py
[2025-07-25T17:10:42.628+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:10:42.627+0700] {dag.py:3036} INFO - Sync 6 DAGs
[2025-07-25T17:10:42.847+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:10:42.846+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1 to None, run_after=None
[2025-07-25T17:10:42.912+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:10:42.911+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_and_2 to None, run_after=None
[2025-07-25T17:10:42.970+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:10:42.970+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_1_never_scheduled to None, run_after=None
[2025-07-25T17:10:43.029+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:10:43.029+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_consumes_unknown_never_scheduled to None, run_after=None
[2025-07-25T17:10:43.089+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:10:43.088+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_1 to 2025-07-24 00:00:00+00:00, run_after=2025-07-25 00:00:00+00:00
[2025-07-25T17:10:43.145+0700] {logging_mixin.py:188} INFO - [2025-07-25T17:10:43.145+0700] {dag.py:3823} INFO - Setting next_dagrun for dataset_produces_2 to None, run_after=None
[2025-07-25T17:10:45.342+0700] {processor.py:183} INFO - Processing /home/ngtph/airflow/airflow_venv/lib/python3.11/site-packages/airflow/example_dags/example_datasets.py took 9.552 seconds
